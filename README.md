# ğŸŒŸ **Ollama Chat App**

> A beautifully designed, fully local AI chat experience powered by **Ollama**.

A modern, minimal, and responsive chat interface for interacting with any Ollama-supported LLM â€” including **LLaMA**, **Mistral**, **Qwen**, **DeepSeek**, and more.  
All processing runs **locally on your machine**, ensuring complete privacy and full control.

---

## âœ¨ **Features**
- ğŸ¨ **Elegant UI** â€“ clean, modern, and responsive  
- âš¡ **Local & Fast** â€“ powered directly by Ollama  
- ğŸ”„ **Model Switching** â€“ choose any installed model  
- ğŸ“ **Persistent Chat History**  
- ğŸŒ™ **Dark/Light Mode**  
- ğŸ“± **Fully Responsive** â€“ works on desktop & mobile  
- ğŸ’¬ **Streaming Responses** for a smooth experience  

---

## ğŸ“Œ **Why This App?**

Because running AI **locally** should feel as good as using any cloud-based chat app â€” but with **zero data collection**, **zero dependencies**, and **zero limitations**.

If you want a beautiful, private AI assistant that lives entirely on your machine, this is it.

---

## ğŸ§  **Powered By**
- [Ollama](https://github.com/ollama/ollama)
- Your locally installed models

---

## â­ **Perfect For**
- Personal AI assistant  
- Prompt engineering  
- Experimenting with local models  
- Building your own custom LLM workflows  

---

Enjoy the freedom of local AI â€” with a UI that finally feels great to use.
